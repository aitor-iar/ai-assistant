# AI Assistant

A modern, professional ChatGPT-lite clone with a beautiful UI, built with Python FastAPI backend and React frontend.

## Features

- ğŸš€ **Streaming responses** - See AI responses in real-time as they're generated
- ğŸ¨ **Modern UI** - Professional minimalist design with light/dark themes
- ğŸ“± **Fully Responsive** - Optimized for mobile, tablet, and desktop
- ğŸŒ“ **Dark/Light Mode** - Toggle between themes with persistent preference
- ğŸ“ **Markdown Support** - Rich text rendering with syntax-highlighted code blocks
- ğŸ’¬ **Message Timestamps** - Track conversation timeline
- ğŸ“‹ **Copy Code Blocks** - One-click copy for code snippets
- ğŸ‘¤ **User Avatars** - Visual distinction between user and AI messages
- âš™ï¸ **Custom System Prompts** - Configure the AI's behavior/personality
- ğŸ”’ **Secure** - API key stays on the server, never exposed to the client
- âœ¨ **Quick Suggestions** - Empty state with example prompts to get started

## Tech Stack

- **Backend**: Python + FastAPI + Uvicorn
- **Frontend**: Vite + React + TypeScript + Tailwind CSS
- **Package Manager**: Bun (for frontend)
- **AI**: OpenAI API (gpt-4o-mini)
- **UI Components**: Custom component library with lucide-react icons
- **Markdown**: react-markdown with syntax highlighting
- **Font**: Inter font family

## Getting Started

### Prerequisites

- [Python 3.8+](https://www.python.org/downloads/)
- [Bun](https://bun.sh/) installed (for frontend)
- OpenAI API key

### Installation

1. Clone the repository

2. Install dependencies:
   ```bash
   # Install frontend dependencies
   cd client && bun install
   
   # Install backend dependencies
   cd ../server && pip install -r requirements.txt
   ```

3. Create a `.env` file in the root directory:
   ```bash
   cp .env.example .env
   ```

4. Add your OpenAI API key to the `.env` file:
   ```
   OPENAI_API_KEY=sk-your-api-key-here
   ```

### Development

Run both the server and client concurrently from the root:

```bash
bun run dev
```

This will start:
- Python FastAPI backend server on `http://localhost:3001`
- Vite frontend dev server on `http://localhost:5173`

### Individual Commands

```bash
# Run only the backend (from root)
bun run dev:server

# Run only the frontend (from root)
bun run dev:client

# Or run them separately:
# Backend (from server/ directory)
cd server && python -m uvicorn main:app --reload --port 3001

# Frontend (from client/ directory)
cd client && bun run dev

# Build frontend for production
cd client && bun run build
```

## Project Structure

```
ai-assistant/
â”œâ”€â”€ client/                 # Vite + React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/       # Reusable UI components (Avatar, Button, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel.tsx
â”‚   â”‚   â”‚   â””â”€â”€ MarkdownMessage.tsx
â”‚   â”‚   â”œâ”€â”€ utils/        # Utility functions (theme management)
â”‚   â”‚   â”œâ”€â”€ App.tsx       # Main app component
â”‚   â”‚   â”œâ”€â”€ main.tsx      # Entry point
â”‚   â”‚   â””â”€â”€ types.ts      # TypeScript types
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ server/                 # Python FastAPI backend
â”‚   â”œâ”€â”€ main.py            # FastAPI server with /api/chat endpoint
â”‚   â”œâ”€â”€ requirements.txt   # Python dependencies
â”‚   â””â”€â”€ package.json       # NPM scripts for convenience
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ cleanup-ports.ps1      # Windows script to cleanup ports
â”œâ”€â”€ package.json           # Root scripts
â””â”€â”€ README.md
```

## API

### POST /api/chat

Send messages to the AI and receive streaming responses.

**Request Body:**
```json
{
  "messages": [
    { "role": "user", "content": "Hello!" }
  ],
  "systemPrompt": "You are a helpful assistant." // optional
}
```

**Response:** Server-Sent Events stream with chunks in format:
```
data: {"content":"Hello"}

data: {"content":" there!"}

data: [DONE]
```

### GET /

Health check endpoint.

**Response:**
```json
{
  "status": "ok",
  "message": "AI Assistant API"
}
```

## Development Notes

- The backend uses **FastAPI** with **Uvicorn** ASGI server
- Streaming is handled via `StreamingResponse` with SSE (Server-Sent Events)
- CORS is configured to allow requests from `http://localhost:5173`
- Environment variables are loaded from the root `.env` file
- The frontend proxies API requests to the backend via Vite's proxy configuration

## License

MIT
